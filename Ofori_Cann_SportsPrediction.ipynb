{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kcann340/FIFARegression_Submission/blob/main/Ofori_Cann_SportsPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import xgboost as xgb\n",
        "import pickle\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, VotingRegressor\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold, train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Loading data\n",
        "playertrain_df = pd.read_csv(\"/content/male_players (legacy).csv\") # For training\n",
        "playertest_df = pd.read_csv(\"/content/players_22 (1).csv\") # For testing\n",
        "\n",
        "# Displaying initial data\n",
        "print(playertrain_df.head())\n",
        "print(playertest_df.head())\n",
        "print(playertrain_df.info())\n",
        "print(playertest_df.info())\n",
        "\n",
        "# Checking for missing values\n",
        "print(\"Checking sum of missing value for Players 21 (Train Data):\")\n",
        "print(playertrain_df.isnull().sum())\n",
        "print(\"Checking sum of missing value for Players 22 (Test Data):\")\n",
        "print(playertest_df.isnull().sum())\n",
        "\n",
        "# Dropping columns with more than 30% missing values\n",
        "total_rows_21 = playertrain_df.shape[0]\n",
        "threshold_21 = int(0.3 * total_rows_21)\n",
        "columns_to_drop = [col for col in playertrain_df.columns if playertrain_df[col].isna().sum() > threshold_21]\n",
        "\n",
        "playertrain_df = playertrain_df.drop(columns=columns_to_drop)\n",
        "playertest_df = playertest_df.drop(columns=columns_to_drop)\n",
        "\n",
        "# Further dropping specific columns\n",
        "drop_columns = ['player_url','long_name','dob','body_type','real_face','player_face_url']\n",
        "playertrain_df = playertrain_df.drop(drop_columns, axis=1)\n",
        "playertest_df = playertest_df.drop(drop_columns, axis=1)\n",
        "\n",
        "# Dropping additional columns\n",
        "drop_r_cols = ['short_name', 'player_positions', 'league_name', 'nationality_name', 'ls', 'st', 'rs', 'lw', 'lf', 'cf', 'rf', 'rw', 'lam', 'cam', 'ram',\n",
        "               'lm', 'lcm', 'cm', 'rcm', 'rm', 'lwb', 'ldm', 'cdm', 'rdm', 'rwb', 'lb', 'lcb', 'cb', 'rcb', 'rb', 'gk']\n",
        "playertrain_df = playertrain_df.drop(drop_r_cols, axis=1)\n",
        "playertest_df = playertest_df.drop(drop_r_cols, axis=1)\n",
        "\n",
        "# Aligning the columns of the training and test datasets\n",
        "playertest_df = playertest_df.reindex(columns=playertrain_df.columns, fill_value=np.nan)\n",
        "\n",
        "# Imputing missing values\n",
        "num_imputer = SimpleImputer(strategy='mean')\n",
        "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "num_features = playertrain_df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "cat_features = playertrain_df.select_dtypes(include=[object]).columns.tolist()\n",
        "\n",
        "# Removing the target variable from the feature list\n",
        "num_features.remove('overall')\n",
        "\n",
        "# Imputing numerical and categorical data for training data\n",
        "playertrain_df[num_features] = num_imputer.fit_transform(playertrain_df[num_features])\n",
        "playertrain_df[cat_features] = cat_imputer.fit_transform(playertrain_df[cat_features])\n",
        "\n",
        "# Imputing numerical and categorical data for testing data\n",
        "playertest_df[num_features] = num_imputer.transform(playertest_df[num_features])\n",
        "playertest_df[cat_features] = cat_imputer.transform(playertest_df[cat_features])\n",
        "\n",
        "# One-hot encoding categorical features\n",
        "playertrain_encoded_df = pd.get_dummies(playertrain_df, columns=cat_features, drop_first=True)\n",
        "playertest_encoded_df = pd.get_dummies(playertest_df, columns=cat_features, drop_first=True)\n",
        "\n",
        "# Aligning test set to training set\n",
        "playertest_encoded_df = playertest_encoded_df.reindex(columns=playertrain_encoded_df.columns, fill_value=0)\n"
      ],
      "metadata": {
        "id": "EwBUr8jRolMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = playertrain_encoded_df.drop(columns=['overall'])\n",
        "y = playertrain_encoded_df['overall']\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=69)\n",
        "\n",
        "# Scaling features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Saving the scaler\n",
        "with open('scaler.pkl', 'wb') as file:\n",
        "    pickle.dump(scaler, file)\n"
      ],
      "metadata": {
        "id": "i0qjBmBiolss"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, param_grid, X, y):\n",
        "    cv = KFold(n_splits=7, random_state=69, shuffle=True)\n",
        "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
        "    grid_search.fit(X, y)\n",
        "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "    print(f\"Best score (MAE): {-grid_search.best_score_}\")\n",
        "    return grid_search.best_estimator_\n",
        "\n",
        "print(\"\\nTraining XGBoost...\")\n",
        "xgb_model = xgb.XGBRegressor(random_state=42)\n",
        "xgb_params = {\n",
        "    'n_estimators': [100, 500, 1000],\n",
        "    'learning_rate': [0.1, 0.001, 0.01],\n",
        "    'max_depth': [3, 5, 9, 15],\n",
        "    'colsample_bytree': [0.5, 0.75, 1]\n",
        "}\n",
        "best_xgb = train_model(xgb_model, xgb_params, X_train_scaled, y_train)\n",
        "\n",
        "print(\"\\nTraining Gradient Boosting...\")\n",
        "gbr_model = GradientBoostingRegressor(random_state=63)\n",
        "gbr_params = {\n",
        "    'n_estimators': [100, 500, 1000],\n",
        "    'learning_rate': [0.1, 0.001, 0.01],\n",
        "    'max_depth': [9, 15]\n",
        "}\n",
        "best_gbr = train_model(gbr_model, gbr_params, X_train_scaled, y_train)\n",
        "\n",
        "print(\"\\nTraining Random Forest...\")\n",
        "rf_model = RandomForestRegressor(random_state=39)\n",
        "rf_params = {\n",
        "    'n_estimators': [500, 1000],\n",
        "    'max_depth': [12, 15],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "best_rf = train_model(rf_model, rf_params, X_train_scaled, y_train)\n",
        "\n",
        "# Creating an ensemble model\n",
        "ensemble = VotingRegressor(\n",
        "    estimators=[\n",
        "        ('xgb', best_xgb),\n",
        "        ('gbr', best_gbr),\n",
        "        ('rf', best_rf)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Fitting model on the training data\n",
        "print(\"\\nTraining Ensemble Model...\")\n",
        "ensemble.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predicting and evaluating on the training set\n",
        "train_pred = ensemble.predict(X_train_scaled)\n",
        "train_mae = mean_absolute_error(y_train, train_pred)\n",
        "print(f\"Ensemble model MAE on training set: {train_mae}\")\n",
        "\n",
        "# Saving models\n",
        "with open('best_xgb_model.pkl', 'wb') as file:\n",
        "    pickle.dump(best_xgb, file)\n",
        "\n",
        "with open('best_gbr_model.pkl', 'wb') as file:\n",
        "    pickle.dump(best_gbr, file)\n",
        "\n",
        "with open('best_rf_model.pkl', 'wb') as file:\n",
        "    pickle.dump(best_rf, file)\n",
        "\n",
        "with open('ensemble_model.pkl', 'wb') as file:\n",
        "    pickle.dump(ensemble, file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjmucS5Qoly9",
        "outputId": "4bd23185-b438-4c73-e1e4-cf929616834c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training XGBoost...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model_on_test(model, X_test, y_test, model_name):\n",
        "    predictions = model.predict(X_test)\n",
        "    mae = mean_absolute_error(y_test, predictions)\n",
        "    print(f\"{model_name} model MAE on test set: {mae:.2f}\")\n",
        "\n",
        "print(\"\\nEvaluating XGBoost...\")\n",
        "evaluate_model_on_test(best_xgb, X_test_scaled, y_test, \"XGBoost\")\n",
        "\n",
        "print(\"\\nEvaluating Gradient Boosting...\")\n",
        "evaluate_model_on_test(best_gbr, X_test_scaled, y_test, \"Gradient Boosting\")\n",
        "\n",
        "print(\"\\nEvaluating Random Forest...\")\n",
        "evaluate_model_on_test(best_rf, X_test_scaled, y_test, \"Random Forest\")\n",
        "\n",
        "print(\"\\nEvaluating Ensemble...\")\n",
        "evaluate_model_on_test(ensemble, X_test_scaled, y_test, \"Ensemble\")\n",
        "\n",
        "# Evaluating models with players_22 dataset\n",
        "X_22 = playertest_encoded_df.drop(columns=['overall'])\n",
        "y_22 = playertest_encoded_df['overall']\n",
        "X_scaled_22 = scaler.transform(X_22)\n",
        "\n",
        "# Loading models\n",
        "with open('best_xgb_model.pkl', 'rb') as file:\n",
        "    lbest_xgb = pickle.load(file)\n",
        "\n",
        "with open('best_gbr_model.pkl', 'rb') as file:\n",
        "    lbest_gbr = pickle.load(file)\n",
        "\n",
        "with open('best_rf_model.pkl', 'rb') as file:\n",
        "    lbest_rf = pickle.load(file)\n",
        "\n",
        "with open('ensemble_model.pkl', 'rb') as file:\n",
        "    lensemble = pickle.load(file)\n",
        "\n",
        "print(\"\\nEvaluating XGBoost on Players 22...\")\n",
        "evaluate_model_on_test(lbest_xgb, X_scaled_22, y_22, \"XGBoost\")\n",
        "\n",
        "print(\"\\nEvaluating Gradient Boosting on Players 22...\")\n",
        "evaluate_model_on_test(lbest_gbr, X_scaled_22, y_22, \"Gradient Boosting\")\n",
        "\n",
        "print(\"\\nEvaluating Random Forest on Players 22...\")\n",
        "evaluate_model_on_test(lbest_rf, X_scaled_22, y_22, \"Random Forest\")\n",
        "\n",
        "print(\"\\nEvaluating Ensemble on Players 22...\")\n",
        "evaluate_model_on_test(lensemble, X_scaled_22, y_22, \"Ensemble\")\n"
      ],
      "metadata": {
        "id": "h0UNSN-eol1j"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}